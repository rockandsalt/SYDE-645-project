{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dataloader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Cs = np.logspace(-1,2,5)\n",
    "pca_red = np.logspace(1.38,np.log10(64**3)/np.log10(10),20).astype(int)\n",
    "df = pd.DataFrame(index = pca_red,columns=Cs)\n",
    "\n",
    "df.loc[23,0.1] = 3\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '.\\tests\\test_output\\data.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-15e09d8f023b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tests'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test_output'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'data.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '.\\tests\\test_output\\data.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "data_path = os.path.join('.','tests','test_output','data.hdf5')\n",
    "\n",
    "dat = h5py.File(data_path, 'r')\n",
    "\n",
    "X = np.array(dat.get('data'))\n",
    "Y = np.array(dat.get('data_label'))\n",
    "dat.close()\n",
    "Cs = np.logspace(-1,2,5)\n",
    "pca_red = np.logspace(1.38,np.log10(64**3)/np.log10(10),10).astype(int)\n",
    "\n",
    "mean_lin_df = pd.DataFrame(index = pca_red,columns=Cs)\n",
    "var_lin_df = pd.DataFrame(index = pca_red,columns=Cs)\n",
    "\n",
    "\n",
    "#for c in Cs:\n",
    "#    for comp in pca_red:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "linear_svc = SVC(C = 10, kernel = 'linear',gamma = 'auto')\n",
    "linear_svc.fit(X_train,y_train)\n",
    "\n",
    "score_lin = linear_svc.score(X_test,y_test)\n",
    "\n",
    "print(score_lin)\n",
    "        \n",
    "\n",
    "\n",
    "# Number of features to take \n",
    "\n",
    "featurenum_list = [10, 100, 1000, 10000, 100000] \n",
    "\n",
    "# Transform the data using PCA \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca_list=[]\n",
    "for x in featurenum_list: \n",
    "    pca = PCA(n_components=x)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    pca_list.append(X_pca)\n",
    "\n",
    "# Transform the data using LDA, not for loop needed, only take feature numbers is #(labels - 1)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda_list=[] \n",
    "lda = LDA()\n",
    "lda.fit(X,Y)\n",
    "X_lda = lda.transform(X)\n",
    "lda_list.append(X_lda)\n",
    "\n",
    "#Select the best features \n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "# Try for different k \n",
    "selkb_list = [] \n",
    "for x in featurenum_list:\n",
    "    X_selkbest = SelectKBest(chi2, k=x).fit_transform(X, Y)\n",
    "    selkb_list.append(X_selkbest)\n",
    "    \n",
    "######################## Decision Tree \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "for x in selkb_list: # or pca_list\n",
    "    Decacc = [] \n",
    "    rkfDec = RepeatedKFold(n_splits=10, n_repeats=10, random_state=None)\n",
    "    for train_index, test_index in rkfDec.split(x):\n",
    "        X_train, X_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index] \n",
    "        clfDec = tree.DecisionTreeClassifier()\n",
    "        clfDec = clf.fit(X_train, y_train)\n",
    "        Decacc.append(clfDec.score(X_test,y_test)*100)    \n",
    "    print(\"For SELKB n =\",x,\"mean =\",np.mean(Decacc),\"var =\",np.var(Decacc))  \n",
    "    \n",
    "for x in pca_list: # or pca_list\n",
    "    Decacc = [] \n",
    "    rkfDec = RepeatedKFold(n_splits=10, n_repeats=10, random_state=None)\n",
    "    for train_index, test_index in rkfDec.split(x):\n",
    "        X_train, X_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index] \n",
    "        clfDec = tree.DecisionTreeClassifier()\n",
    "        clfDec = clf.fit(X_train, y_train)\n",
    "        Decacc.append(clfDec.score(X_test,y_test)*100)    \n",
    "    print(\"For PCA, n =\",x,\"mean =\",np.mean(Decacc),\"var =\",np.var(Decacc))\n",
    "\n",
    "####################### KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "K = [1, 3, 5, 11]\n",
    "for x in selkb_list: # \n",
    "    for k in K: \n",
    "        KNNacc = [] \n",
    "        rkfKNN = RepeatedKFold(n_splits=10, n_repeats=10, random_state=None)\n",
    "        for train_index, test_index in rkfKNN.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = Y[train_index], Y[test_index] \n",
    "            clfKNN = KNeighborsClassifier(n_neighbors=k)\n",
    "            clfKNN = clfKNN.fit(X_train, y_train)\n",
    "            KNNacc.append(clfKNN.score(X_test,y_test)*100)\n",
    "        print(\"For SELKB n =\",x,\"k=\",k,\"mean =\",np.mean(KNNacc),\"var =\",np.var(KNNacc))  \n",
    "\n",
    "for x in pca_list: # or pca_list\n",
    "    for k in K: \n",
    "        KNNacc = [] \n",
    "        rkfKNN = RepeatedKFold(n_splits=10, n_repeats=10, random_state=None)\n",
    "        for train_index, test_index in rkfKNN.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = Y[train_index], Y[test_index] \n",
    "            clfKNN = KNeighborsClassifier(n_neighbors=k)\n",
    "            clfKNN = clfKNN.fit(X_train, y_train)\n",
    "            KNNacc.append(clfKNN.score(X_test,y_test)*100)\n",
    "        print(\"For PCA n =\",x,\"k=\",k,\"mean =\",np.mean(KNNacc),\"var =\",np.var(KNNacc))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "print(mp.cpu_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
