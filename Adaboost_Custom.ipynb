{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# For charts \n",
    "from sklearn import svm \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "\n",
    "# Libraries for analysis \n",
    "import pandas as pd\n",
    "import xlrd \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "from numpy.random import choice\n",
    "import math \n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "data_path = os.path.join('.','tests','test_output')\n",
    "\n",
    "X = np.load(os.path.join(data_path,'x_split_alt_0.npy'),mmap_mode='r')\n",
    "Y = np.load(os.path.join(data_path,'y_split_alt_0.npy'),mmap_mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # The following function take as inputs the weights \n",
    "#data(for each symbol), the samples \n",
    "# to test ,and their labels   \n",
    "def adaboostM1(XX,yy,weights_data):\n",
    "    # List of classifiers \n",
    "    list_clf =[]\n",
    "    # List of classifiers constants \n",
    "    list_clfwei = [] \n",
    "    \n",
    "    T = 50 # maximum number of classifiers\n",
    "    t =0 \n",
    "    while t < T:\n",
    "        Length_data = range(len(XX)) \n",
    "        \n",
    "        # Selecting a specific number of samples\n",
    "        Samples = choice(Length_data,100,True,weights_data) \n",
    "        examples =XX[Samples]\n",
    "        labels = yy[Samples]\n",
    "\n",
    "        # Train classifier on those examples\n",
    "        clfAda = (svm.SVC(kernel='linear', C=0.1))\n",
    "        clfAda.fit(examples,labels)\n",
    "\n",
    "        # Get error \n",
    "        error = 1 - clfAda.score(XX,yy,weights_data)\n",
    "        \n",
    "        # Establish condition to skip rest of the loop \n",
    "        if (error>0.5):\n",
    "            continue\n",
    "    \n",
    "        # Find Beta\n",
    "        B_t = error/(1-error); \n",
    "\n",
    "        # Predict label for the whole data set\n",
    "        guesses = clfAda.predict(XX)\n",
    "        \n",
    "        # Compare predictions to actual labels\n",
    "        for i in range(len(guesses)):\n",
    "            if yy[i] == guesses[i]:\n",
    "                # Penalize the weights of the data when its right\n",
    "                weights_data[i] = B_t*weights_data[i]; \n",
    "\n",
    "        # Normalize the data \n",
    "        sumofweights = sum(weights_data)\n",
    "        weights_data = [x/sumofweights for x in weights_data]   \n",
    "\n",
    "        # We have 50 classifiers in total, each one has a constant\n",
    "        list_clf.append(clfAda)\n",
    "        list_clfwei.append(math.log(1/B_t,2))\n",
    "        t= t+1\n",
    "        \n",
    "    return list_clf, list_clfwei\n",
    " # Let's have 50 lists that we can multiply to get one final lists \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "def compute(XX,yy,Xt,yt): \n",
    "    # Runs the adaboost, takes as inputs the values the inputs the \n",
    "    #training data and the \n",
    "    #validation data as well \n",
    "    # Re-initialize the weights \n",
    "    weights_data = [1/len(XX)]*len(XX)\n",
    "    # Now compute the accuracy for the ensemble classifier     \n",
    "    list_clf, list_clfwei =  adaboostM1(XX,yy,weights_data)\n",
    "    \n",
    "    # Guess all data and add it\n",
    "    guesses2 = 0 \n",
    "    \n",
    "\n",
    "    d = np.zeros((len(Xt),len(np.unique(yt))))\n",
    "\n",
    "    for i in range(len(list_clf)):       \n",
    "        l = list_clf[i].predict(Xt) \n",
    "        r = np.asmatrix(l)\n",
    "        \n",
    "        for j in range(r.size):\n",
    "            d[j,r[0,j]] += list_clfwei[i]\n",
    "        \n",
    "    guesses2 = np.argmax(d, axis=1)\n",
    "\n",
    "\n",
    "    # Compute the signs of all outputs \n",
    "    acc = 0 \n",
    "    \n",
    "    # Check how the guesses compare to the actual number\n",
    "    for i in range(len(guesses2)):\n",
    "        if yt[i] == guesses2[i]:\n",
    "            acc = acc+1  \n",
    "    acc = acc/len(guesses2)\n",
    "    return acc\n",
    "\n",
    "listacc = [] \n",
    "\n",
    "# Do the 10 times 10 fold cross-validation using the \"computing\" function\n",
    "rkf2 = RepeatedKFold(n_splits=2, n_repeats=1, random_state=None)\n",
    "for train_index, test_index in rkf2.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    listacc.append(compute(X_train,y_train,X_test,y_test))\n",
    "    \n",
    "# Finalize and print results\n",
    "listacc = [x*100 for x in listacc]\n",
    "print(\"The variance as a percentage is\", np.var(listacc))\n",
    "print(\"The mean as a percentage is\", np.mean(listacc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
